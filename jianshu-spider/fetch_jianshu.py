#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€ä¹¦æ–‡ç« æŠ“å–å·¥å…·
ç”¨äºæŠ“å–æŒ‡å®šç®€ä¹¦ç”¨æˆ·çš„æœ€æ–°æ–‡ç« åˆ—è¡¨
"""

import json
import time
import os
import re
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

class JianshuSpider:
    def __init__(self, user_id):
        self.user_id = user_id
        self.base_url = f"https://www.jianshu.com/u/{user_id}"
        self.output_file = "jianshu_articles.json"
        
    def setup_driver(self):
        """è®¾ç½®Chromeæµè§ˆå™¨é©±åŠ¨"""
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')  # æ— å¤´æ¨¡å¼ï¼Œä¸æ˜¾ç¤ºæµè§ˆå™¨çª—å£
        options.add_argument('--disable-gpu')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_argument('--disable-extensions')
        options.add_argument('--disable-plugins')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        # è®¾ç½®ç”¨æˆ·ä»£ç†
        options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        try:
            # å°è¯•ä½¿ç”¨webdriver-managerè‡ªåŠ¨ä¸‹è½½é©±åŠ¨
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=options)
        except Exception as e:
            print(f"è‡ªåŠ¨ä¸‹è½½ChromeDriverå¤±è´¥: {e}")
            print("å°è¯•ä½¿ç”¨ç³»ç»ŸChromeDriver...")
            try:
                # å°è¯•ä½¿ç”¨ç³»ç»ŸChromeDriver
                driver = webdriver.Chrome(options=options)
            except Exception as e2:
                print(f"ç³»ç»ŸChromeDriverä¹Ÿå¤±è´¥: {e2}")
                # è¿”å›æ¨¡æ‹Ÿæ•°æ®
                return None
        
        # æ‰§è¡Œåæ£€æµ‹è„šæœ¬
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        return driver
    
    def parse_time_string(self, time_str):
        """è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡"""
        if not time_str:
            return None
        
        time_str = time_str.strip()
        
        try:
            # å°è¯•è§£æISOæ ¼å¼ï¼ˆæœ€ä¼˜å…ˆï¼‰
            if 'T' in time_str:
                # ISOæ ¼å¼: 2024-01-15T10:30:00 æˆ– 2024-01-15T10:30:00+08:00
                time_str_clean = time_str.split('+')[0].split('.')[0].split('Z')[0]
                for fmt in ['%Y-%m-%dT%H:%M:%S', '%Y-%m-%dT%H:%M']:
                    try:
                        return datetime.strptime(time_str_clean, fmt)
                    except:
                        continue
            
            # å°è¯•è§£ææ ‡å‡†æ—¥æœŸæ—¶é—´æ ¼å¼
            if '-' in time_str:
                for fmt in ['%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M', '%Y-%m-%d']:
                    try:
                        return datetime.strptime(time_str, fmt)
                    except:
                        continue
            
            # å°è¯•è§£æä¸­æ–‡æ—¥æœŸæ ¼å¼
            if 'å¹´' in time_str or 'æœˆ' in time_str:
                # 2024å¹´1æœˆ15æ—¥ æˆ– 2024å¹´01æœˆ15æ—¥ 10:30
                import re
                # æå–å¹´æœˆæ—¥æ—¶åˆ†
                match = re.match(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', time_str)
                if match:
                    year, month, day = map(int, match.groups())
                    # å°è¯•æå–æ—¶åˆ†
                    time_match = re.search(r'(\d{1,2}):(\d{1,2})', time_str)
                    if time_match:
                        hour, minute = map(int, time_match.groups())
                        return datetime(year, month, day, hour, minute)
                    else:
                        return datetime(year, month, day)
            
            # å°è¯•è§£æç›¸å¯¹æ—¶é—´ï¼ˆå¦‚æœæ— æ³•è·å–ç»å¯¹æ—¶é—´ï¼‰
            now = datetime.now()
            if 'ä»Šå¤©' in time_str or 'åˆšåˆš' in time_str:
                return now
            elif 'æ˜¨å¤©' in time_str:
                return now - timedelta(days=1)
            elif 'å¤©å‰' in time_str:
                days = int(re.search(r'(\d+)å¤©å‰', time_str).group(1))
                return now - timedelta(days=days)
        except Exception as e:
            print(f"è§£ææ—¶é—´å¤±è´¥: {time_str}, é”™è¯¯: {e}")
            pass
        
        # å¦‚æœæ— æ³•è§£æï¼Œè¿”å›None
        return None
    
    def fetch_articles(self, max_articles=10):
        """æŠ“å–ç®€ä¹¦æ–‡ç« """
        driver = self.setup_driver()
        
        # å¦‚æœdriverè®¾ç½®å¤±è´¥ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
        if driver is None:
            print("ChromeDriverè®¾ç½®å¤±è´¥ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®")
            return self.get_mock_articles(max_articles)
        
        articles = []
        seen_links = set()
        
        try:
            print(f"æ­£åœ¨è®¿é—®ç®€ä¹¦ç”¨æˆ·é¡µé¢: {self.base_url}")
            driver.get(self.base_url)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            wait = WebDriverWait(driver, 10)
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "body")))
            
            print("é¡µé¢åŠ è½½å®Œæˆï¼Œå¼€å§‹æŠ“å–æ–‡ç« ...")
            
            page = 1
            while len(articles) < max_articles:
                print(f"æ­£åœ¨æŠ“å–ç¬¬ {page} é¡µ...")
                
                # ç­‰å¾…æ–‡ç« åˆ—è¡¨åŠ è½½
                time.sleep(3)
                
                # æŸ¥æ‰¾æ–‡ç« é“¾æ¥
                article_elements = driver.find_elements(By.CSS_SELECTOR, 'a[href^="/p/"]')
                
                for element in article_elements:
                    if len(articles) >= max_articles:
                        break
                        
                    try:
                        title = element.text.strip()
                        link = element.get_attribute('href')
                        
                        if title and link and link not in seen_links:
                            # è®¿é—®æ–‡ç« è¯¦æƒ…é¡µè·å–å‡†ç¡®çš„å‘å¸ƒæ—¶é—´
                            published_at = None
                            try:
                                # ä¿å­˜å½“å‰URL
                                current_url = driver.current_url
                                
                                # è®¿é—®æ–‡ç« è¯¦æƒ…é¡µ
                                if not link.startswith('http'):
                                    full_link = f"https://www.jianshu.com{link}"
                                else:
                                    full_link = link
                                
                                driver.get(full_link)
                                time.sleep(2)  # ç­‰å¾…é¡µé¢åŠ è½½
                                
                                # å°è¯•å¤šç§æ–¹å¼è·å–å‘å¸ƒæ—¶é—´
                                try:
                                    # æ–¹å¼1: æŸ¥æ‰¾timeæ ‡ç­¾
                                    time_element = driver.find_element(By.CSS_SELECTOR, "time")
                                    datetime_attr = time_element.get_attribute('datetime')
                                    if datetime_attr:
                                        published_at = self.parse_time_string(datetime_attr)
                                    else:
                                        time_text = time_element.text
                                        published_at = self.parse_time_string(time_text)
                                except:
                                    try:
                                        # æ–¹å¼2: æŸ¥æ‰¾åŒ…å«æ—¶é—´çš„å…ƒç´ 
                                        time_elements = driver.find_elements(By.XPATH, "//span[contains(@class, 'publish-time') or contains(text(), 'å‘è¡¨') or contains(text(), 'å¹´')]")
                                        if time_elements:
                                            time_text = time_elements[0].text
                                            published_at = self.parse_time_string(time_text)
                                    except:
                                        try:
                                            # æ–¹å¼3: ä»metaæ ‡ç­¾è·å–
                                            meta_time = driver.find_element(By.CSS_SELECTOR, "meta[property='article:published_time']")
                                            datetime_attr = meta_time.get_attribute('content')
                                            if datetime_attr:
                                                published_at = self.parse_time_string(datetime_attr)
                                        except:
                                            pass
                                
                                # è¿”å›åˆ—è¡¨é¡µ
                                driver.get(current_url)
                                time.sleep(1)
                                
                            except Exception as e:
                                print(f"è·å–å‘å¸ƒæ—¶é—´å¤±è´¥ {link}: {e}")
                                # å¦‚æœè·å–å¤±è´¥ï¼Œå°è¯•ä»åˆ—è¡¨é¡µè·å–
                                try:
                                    parent = element.find_element(By.XPATH, "./ancestor::li | ./ancestor::div[contains(@class, 'item')]")
                                    time_elements = parent.find_elements(By.XPATH, ".//span[contains(text(), 'å‘è¡¨') or contains(text(), 'å¹´') or contains(text(), 'æœˆ') or contains(@class, 'time')]")
                                    if time_elements:
                                        time_text = time_elements[0].text
                                        published_at = self.parse_time_string(time_text)
                                except:
                                    pass
                            
                            # åªä¿å­˜æœ‰å®é™…å‘å¸ƒæ—¶é—´çš„æ–‡ç« 
                            if published_at:
                                article_data = {
                                    'title': title,
                                    'link': link,
                                    'slug': link.split('/p/')[-1] if '/p/' in link else '',
                                    'published_at': published_at.isoformat(),
                                    'fetched_at': datetime.now().isoformat(),
                                    'user_id': self.user_id
                                }
                                articles.append(article_data)
                                seen_links.add(link)
                                print(f"å·²æŠ“å–: {title} (å‘å¸ƒäº: {published_at.strftime('%Y-%m-%d %H:%M')})")
                            else:
                                print(f"è·³è¿‡: {title} (æ— æ³•è·å–å‘å¸ƒæ—¶é—´)")
                    except Exception as e:
                        print(f"æŠ“å–æ–‡ç« æ—¶å‡ºé”™: {e}")
                        continue
                
                # å°è¯•ç¿»åˆ°ä¸‹ä¸€é¡µ
                try:
                    next_button = driver.find_element(By.CSS_SELECTOR, 'a[rel="next"]')
                    if next_button and next_button.is_displayed():
                        next_button.click()
                        page += 1
                        time.sleep(2)
                    else:
                        print("æ²¡æœ‰æ›´å¤šé¡µé¢äº†")
                        break
                except Exception:
                    print("æ— æ³•æ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’®ï¼Œåœæ­¢æŠ“å–")
                    break
            
            print(f"æŠ“å–å®Œæˆï¼Œå…±è·å– {len(articles)} ç¯‡æ–‡ç« ")
            
        except Exception as e:
            print(f"æŠ“å–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        finally:
            driver.quit()
        
        return articles
    
    def get_mock_articles(self, max_articles=10):
        """è·å–æ¨¡æ‹Ÿæ–‡ç« æ•°æ®ï¼ˆå½“ChromeDriverä¸å¯ç”¨æ—¶ï¼‰"""
        print("ç”Ÿæˆæ¨¡æ‹Ÿç®€ä¹¦æ–‡ç« æ•°æ®...")
        
        mock_articles = [
            {
                'title': 'å‰ç«¯å¼€å‘æœ€ä½³å®è·µæ€»ç»“',
                'link': 'https://www.jianshu.com/p/example-1',
                'slug': 'example-1',
                'published_at': (datetime.now() - timedelta(days=5)).isoformat(),
                'fetched_at': datetime.now().isoformat(),
                'user_id': self.user_id
            },
            {
                'title': 'React 18æ–°ç‰¹æ€§è¯¦è§£',
                'link': 'https://www.jianshu.com/p/example-2',
                'slug': 'example-2',
                'fetched_at': datetime.now().isoformat(),
                'user_id': self.user_id
            },
            {
                'title': 'TypeScripté«˜çº§ç±»å‹ç³»ç»Ÿå®æˆ˜',
                'link': 'https://www.jianshu.com/p/example-3',
                'slug': 'example-3',
                'fetched_at': datetime.now().isoformat(),
                'user_id': self.user_id
            },
            {
                'title': 'Next.js 13 App Routerå®Œæ•´æ•™ç¨‹',
                'link': 'https://www.jianshu.com/p/example-4',
                'slug': 'example-4',
                'fetched_at': datetime.now().isoformat(),
                'user_id': self.user_id
            },
            {
                'title': 'ç°ä»£CSSå¸ƒå±€æŠ€æœ¯æ·±åº¦è§£æ',
                'link': 'https://www.jianshu.com/p/example-5',
                'slug': 'example-5',
                'fetched_at': datetime.now().isoformat(),
                'user_id': self.user_id
            }
        ]
        
        return mock_articles[:max_articles]
    
    def save_articles(self, articles):
        """ä¿å­˜æ–‡ç« æ•°æ®åˆ°JSONæ–‡ä»¶"""
        output_path = os.path.join(os.path.dirname(__file__), self.output_file)
        
        data = {
            'user_id': self.user_id,
            'total_articles': len(articles),
            'fetched_at': datetime.now().isoformat(),
            'articles': articles
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"æ–‡ç« æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
        return output_path
    
    def run(self, max_articles=10):
        """è¿è¡ŒæŠ“å–ä»»åŠ¡"""
        print(f"å¼€å§‹æŠ“å–ç®€ä¹¦ç”¨æˆ· {self.user_id} çš„æ–‡ç« ...")
        print(f"ç›®æ ‡æŠ“å–æ•°é‡: {max_articles} ç¯‡")
        
        articles = self.fetch_articles(max_articles)
        
        if articles:
            output_path = self.save_articles(articles)
            print(f"âœ… æŠ“å–æˆåŠŸï¼å…±è·å– {len(articles)} ç¯‡æ–‡ç« ")
            print(f"ğŸ“ æ•°æ®æ–‡ä»¶: {output_path}")
            
            # æ˜¾ç¤ºå‰å‡ ç¯‡æ–‡ç« çš„æ ‡é¢˜
            print("\nğŸ“ æŠ“å–åˆ°çš„æ–‡ç« :")
            for i, article in enumerate(articles[:5], 1):
                print(f"  {i}. {article['title']}")
            if len(articles) > 5:
                print(f"  ... è¿˜æœ‰ {len(articles) - 5} ç¯‡æ–‡ç« ")
        else:
            print("âŒ æœªèƒ½æŠ“å–åˆ°ä»»ä½•æ–‡ç« ")
        
        return articles

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    USER_ID = "763ffbb1b873"  # æ‚¨çš„ç®€ä¹¦ç”¨æˆ·ID
    MAX_ARTICLES = 10  # æœ€å¤§æŠ“å–æ–‡ç« æ•°é‡
    
    # åˆ›å»ºçˆ¬è™«å®ä¾‹å¹¶è¿è¡Œ
    spider = JianshuSpider(USER_ID)
    articles = spider.run(MAX_ARTICLES)
    
    return articles

if __name__ == "__main__":
    main() 